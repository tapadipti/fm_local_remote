train:
  batch_size: 128
  hidden_units: 128
  dropout: 0.45
  num_epochs: 2
  lr: 0.001
  conv_activation: relu